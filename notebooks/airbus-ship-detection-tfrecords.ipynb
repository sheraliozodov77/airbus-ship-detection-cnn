{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c7490e5f-6ce1-4ac9-a0f8-eac1517c574a",
    "_uuid": "51be8f7e-5d8d-4ea4-aa15-ae8cb1991c4c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-24T06:50:00.838975Z",
     "iopub.status.busy": "2025-03-24T06:50:00.838595Z",
     "iopub.status.idle": "2025-03-24T06:50:15.105547Z",
     "shell.execute_reply": "2025-03-24T06:50:15.104850Z",
     "shell.execute_reply.started": "2025-03-24T06:50:00.838929Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os, gc, math, cv2, pandas as pd, numpy as np, tensorflow as tf\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Enable garbage collection and suppress warnings for clean output\n",
    "gc.enable()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d3f61a19-b491-4b9a-baeb-ce8ae8057b77",
    "_uuid": "89fc26a5-0650-4634-afb8-8704a39231b2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-03-24T06:50:15.107019Z",
     "iopub.status.busy": "2025-03-24T06:50:15.106489Z",
     "iopub.status.idle": "2025-03-24T06:50:15.110907Z",
     "shell.execute_reply": "2025-03-24T06:50:15.110037Z",
     "shell.execute_reply.started": "2025-03-24T06:50:15.106988Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set Global Parameters & Paths\n",
    "IMAGE_SIZE = (384, 384)\n",
    "TRAIN_DIR = \"train_v2\"\n",
    "CSV_PATH = \"train_ship_segmentations_v2.csv\"\n",
    "OUTPUT_DIR = \"./tfrecords\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "NUM_SHARDS = 30\n",
    "SAMPLED_NO_SHIPS = 8000\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    \"\"\"\n",
    "    Decode a run-length encoded (RLE) string into a 2D binary mask.\n",
    "    \n",
    "    Parameters:\n",
    "        mask_rle (str): The run-length encoded mask string.\n",
    "        shape (tuple): The shape of the mask (height, width).\n",
    "    \n",
    "    Returns:\n",
    "        mask (ndarray): 2D binary mask array (values 0 or 1), transposed.\n",
    "    \"\"\"\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[::2], s[1::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    mask = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        mask[lo:hi] = 1\n",
    "    return mask.reshape(shape).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, mask):\n",
    "    \"\"\"\n",
    "    Resize the image and mask to the target IMAGE_SIZE.\n",
    "    \n",
    "    Parameters:\n",
    "        image (ndarray): Original image array.\n",
    "        mask (ndarray): Original mask array.\n",
    "    \n",
    "    Returns:\n",
    "        image, mask: Resized image and binary mask as uint8.\n",
    "    \"\"\"\n",
    "    image = resize(image, IMAGE_SIZE, preserve_range=True, anti_aliasing=True).astype(np.uint8)\n",
    "    mask = resize(mask, IMAGE_SIZE, preserve_range=True, anti_aliasing=False, order=0).astype(np.uint8)\n",
    "    mask = (mask > 0).astype(np.uint8)\n",
    "    return image, mask\n",
    "\n",
    "def create_tf_example(image_id, df):\n",
    "    \"\"\"\n",
    "    Create a TFRecord Example for a given image.\n",
    "    \n",
    "    Reads the image and corresponding RLE-encoded mask(s), decodes the masks,\n",
    "    preprocesses the image and mask (resizing, type conversion), and encodes them.\n",
    "    \n",
    "    Parameters:\n",
    "        image_id (str): Filename of the image.\n",
    "        df (DataFrame): DataFrame containing RLE mask information.\n",
    "    \n",
    "    Returns:\n",
    "        tf.train.Example containing image bytes, mask bytes, and additional metadata.\n",
    "        Returns None if image file is missing or corrupted.\n",
    "    \"\"\"\n",
    "    image_path = os.path.join(TRAIN_DIR, image_id)\n",
    "    if not os.path.exists(image_path): return None\n",
    "\n",
    "    image = imread(image_path)\n",
    "    if image.ndim != 3 or image.shape[2] != 3: return None\n",
    "\n",
    "    rles = df[df['ImageId'] == image_id]['EncodedPixels'].dropna()\n",
    "    mask = np.zeros((768, 768), dtype=np.uint8)\n",
    "    for rle in rles:\n",
    "        mask += rle_decode(rle)\n",
    "    mask = np.clip(mask, 0, 1)\n",
    "\n",
    "    image, mask = preprocess(image, mask)\n",
    "\n",
    "    _, img_buf = cv2.imencode(\".jpg\", image, [int(cv2.IMWRITE_JPEG_QUALITY), 90])\n",
    "    _, mask_buf = cv2.imencode(\".png\", mask)\n",
    "\n",
    "    feature = {\n",
    "        'image_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_id.encode()])),\n",
    "        'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_buf.tobytes()])),\n",
    "        'mask': tf.train.Feature(bytes_list=tf.train.BytesList(value=[mask_buf.tobytes()])),\n",
    "        'has_ship': tf.train.Feature(int64_list=tf.train.Int64List(value=[int(rles.shape[0] > 0)]))\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tfrecord(filename, image_ids, df):\n",
    "    \"\"\"\n",
    "    Write a single TFRecord file with GZIP compression.\n",
    "    \n",
    "    Loops over a list of image_ids, creates a TFRecord Example for each, and writes them.\n",
    "    \n",
    "    Parameters:\n",
    "        filename (str): Output filename for the TFRecord.\n",
    "        image_ids (list): List of image filenames to be written.\n",
    "        df (DataFrame): DataFrame containing RLE mask information.\n",
    "    \n",
    "    Prints the number of samples written.\n",
    "    \"\"\"\n",
    "    options = tf.io.TFRecordOptions(compression_type='GZIP')\n",
    "    count = 0\n",
    "    with tf.io.TFRecordWriter(filename, options=options) as writer:\n",
    "        for img_id in image_ids:\n",
    "            example = create_tf_example(img_id, df)\n",
    "            if example:\n",
    "                writer.write(example.SerializeToString())\n",
    "                count += 1\n",
    "    print(f\"{filename} - {count} samples\")\n",
    "\n",
    "def write_shards(prefix, image_ids, df, num_shards=NUM_SHARDS):\n",
    "    \"\"\"\n",
    "    Split the dataset into multiple shards and write each shard as a TFRecord file.\n",
    "    \n",
    "    Parameters:\n",
    "        prefix (str): Prefix for the output filename (e.g., 'train' or 'val').\n",
    "        image_ids (list): List of image filenames to be processed.\n",
    "        df (DataFrame): DataFrame with RLE data.\n",
    "        num_shards (int): Number of shards/files to create.\n",
    "    \"\"\"\n",
    "    shard_size = math.ceil(len(image_ids) / num_shards)\n",
    "    for i in range(num_shards):\n",
    "        shard_ids = image_ids[i * shard_size: (i + 1) * shard_size]\n",
    "        fname = os.path.join(OUTPUT_DIR, f\"{prefix}_sharded_{i+1:02d}-of-{num_shards}.tfrecord.gz\")\n",
    "        write_tfrecord(fname, shard_ids, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 45500 images\n",
      "Val: 5056 images\n",
      "✅ ./tfrecords/train_sharded_01-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_02-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_03-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_04-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_05-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_06-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_07-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_08-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_09-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_10-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_11-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_12-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_13-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_14-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_15-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_16-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_17-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_18-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_19-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_20-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_21-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_22-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_23-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_24-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_25-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_26-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_27-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_28-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_29-of-30.tfrecord.gz - 1517 samples\n",
      "✅ ./tfrecords/train_sharded_30-of-30.tfrecord.gz - 1507 samples\n",
      "✅ ./tfrecords/val_sharded_01-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_02-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_03-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_04-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_05-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_06-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_07-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_08-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_09-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_10-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_11-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_12-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_13-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_14-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_15-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_16-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_17-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_18-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_19-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_20-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_21-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_22-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_23-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_24-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_25-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_26-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_27-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_28-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_29-of-30.tfrecord.gz - 169 samples\n",
      "✅ ./tfrecords/val_sharded_30-of-30.tfrecord.gz - 155 samples\n"
     ]
    }
   ],
   "source": [
    "# Load CSV & Split Data, then Write TFRecord Shards\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df['has_ship'] = df['EncodedPixels'].notnull()\n",
    "ship_ids = df[df['has_ship']]['ImageId'].unique()\n",
    "no_ship_ids = np.setdiff1d(df['ImageId'].unique(), ship_ids)\n",
    "sampled_no_ship = np.random.choice(no_ship_ids, size=SAMPLED_NO_SHIPS, replace=False)\n",
    "\n",
    "filtered_ids = np.concatenate([ship_ids, sampled_no_ship])\n",
    "train_ids, val_ids = train_test_split(filtered_ids, test_size=0.1, random_state=SEED)\n",
    "\n",
    "print(f\"Train: {len(train_ids)} images\")\n",
    "print(f\"Val: {len(val_ids)} images\")\n",
    "\n",
    "write_shards(\"train\", train_ids, df)\n",
    "write_shards(\"val\", val_ids, df)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 868324,
     "sourceId": 9988,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
